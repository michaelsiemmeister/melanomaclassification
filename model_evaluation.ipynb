{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.metrics import average_precision_score as avp\n",
    "from sklearn.metrics import precision_recall_curve as prc\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.metrics import precision_score, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "\n",
    "import melanoma_classification.melanomaclassification as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure, the directory for storing results exists.\n",
    "os.makedirs('../results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign more concise names to the two test-dataframes\n",
    "isic2016 = mc.isic2016test_std_df\n",
    "mclass = mc.mclass_std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that there are only two labels\n",
    "assert(len(isic2016['category'].unique()) == 2)\n",
    "assert(len(mclass['category'].unique() == 2))\n",
    "\n",
    "# data generators\n",
    "isic2016_gen = mc.resnet50_testDataGen_flow_df(\n",
    "    isic2016,\n",
    "    mc.images_base_path,\n",
    "    batch_size=1,\n",
    "    class_mode='binary')\n",
    "\n",
    "mclass_gen = mc.resnet50_testDataGen_flow_df(\n",
    "    mclass,\n",
    "    mc.images_base_path,\n",
    "    batch_size=1,\n",
    "    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoLayer = tf.keras.models.load_model(\n",
    "    '../models/twoLayer.h5', compile=False)\n",
    "simple = tf.keras.models.load_model(\n",
    "    '../models/simple.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoLayer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using the models and save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells in this section don't have to be run if the results already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoLayer_isic2016_predictions = twoLayer.predict_generator(isic2016_gen)\n",
    "simple_isic2016_predictions = simple.predict_generator(isic2016_gen)\n",
    "# in this case classes returns an array of 0 and 1. 1 for each malignant\n",
    "# image and 0 for each benign image.\n",
    "isic2016['y_true'] = isic2016_gen.classes \n",
    "isic2016['y_score_two_Layer'] = twoLayer_isic2016_predictions\n",
    "isic2016['y_score_simple'] = simple_isic2016_predictions\n",
    "isic2016.to_csv('../results/isic2016_predictions.csv')\n",
    "#isic2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoLayer_mclass_predictions = twoLayer.predict_generator(mclass_gen)\n",
    "simple_mclass_predictions = simple.predict_generator(mclass_gen)\n",
    "mclass['y_true'] = mclass_gen.classes\n",
    "mclass['y_score_two_Layer'] = twoLayer_mclass_predictions\n",
    "mclass['y_score_simple'] = simple_mclass_predictions\n",
    "mclass.to_csv('../results/mclass_predictions.csv')\n",
    "#mclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After executing the first cell, this can be an alternative entry point. \n",
    "If the results already exist, there is no need to predict again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isic2016 = pd.read_csv('../results/isic2016_predictions.csv')\n",
    "mclass = pd.read_csv('../results/mclass_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random-classifier-model:\n",
    "# chooses y_score randomly from a uniform distribution on [0,1].\n",
    "rg = default_rng(123456789)\n",
    "isic_random_y_scores = rg.random(isic2016.y_true.values.shape)\n",
    "mclass_random_y_scores = rg.random(mclass.y_true.values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_score, model_name='NoName'):\n",
    "    '''\n",
    "    y_true and y_score shall be 1-D numpy ndarrays\n",
    "    '''\n",
    "    results_dict = {}\n",
    "    results_dict['model_name'] = model_name\n",
    "    results_dict['average_precision'] = avp(y_true, y_score)\n",
    "    precision, recall, prc_thresholds = prc(y_true, y_score)\n",
    "    results_dict['precision'] = np.flip(precision)\n",
    "    results_dict['recall'] = np.flip(recall)\n",
    "    results_dict['prc_thresholds'] = np.flip(prc_thresholds)\n",
    "    \n",
    "    results_dict['roc_auc'] = roc_auc_score(y_true, y_score)\n",
    "    fpr, tpr, roc_thresholds = roc_curve(y_true, y_score)\n",
    "    results_dict['fpr'] = fpr\n",
    "    results_dict['tpr'] = tpr\n",
    "    results_dict['roc_thresholds'] = roc_thresholds\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isic\n",
    "isic_tL_eval = evaluate_model(isic2016.y_true.values, \n",
    "                                              isic2016.y_score_two_Layer, \n",
    "                                              model_name='twoLayer')\n",
    "isic_tL_eval['color'] = 'b'\n",
    "\n",
    "isic_simple_eval = evaluate_model(isic2016.y_true.values, \n",
    "                                              isic2016.y_score_simple, \n",
    "                                              model_name='simple')\n",
    "\n",
    "isic_simple_eval['color'] = 'r'\n",
    "isic_random_eval = evaluate_model(isic2016.y_true.values,\n",
    "                                  isic_random_y_scores,\n",
    "                                  model_name='random')\n",
    "\n",
    "isic_random_eval['color'] = 'g'\n",
    "\n",
    "\n",
    "# mclass\n",
    "mclass_tL_eval = evaluate_model(mclass.y_true.values, \n",
    "                                              mclass.y_score_two_Layer, \n",
    "                                              model_name='twoLayer')\n",
    "mclass_tL_eval['color'] = 'b'\n",
    "\n",
    "mclass_simple_eval = evaluate_model(mclass.y_true.values, \n",
    "                                              mclass.y_score_simple, \n",
    "                                              model_name='simple')\n",
    "\n",
    "mclass_simple_eval['color'] = 'r'\n",
    "mclass_random_eval = evaluate_model(mclass.y_true.values,\n",
    "                                  mclass_random_y_scores,\n",
    "                                  model_name='random')\n",
    "\n",
    "mclass_random_eval['color'] = 'g'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ISIC2016\\n-------')\n",
    "for model in (isic_tL_eval, isic_simple_eval, isic_random_eval):\n",
    "    print('''Model: {},\n",
    "  Average Precision = {:.4f},\n",
    "  ROC-AUC = {:.4f}'''.format(\n",
    "       model['model_name'], model['average_precision'], model['roc_auc']))\n",
    "    model['dataset'] = 'isic2016'\n",
    "\n",
    "print('\\n\\n')\n",
    "    \n",
    "print('MClass\\n------')\n",
    "for model in (mclass_tL_eval, mclass_simple_eval, mclass_random_eval):\n",
    "    print('''Model: {},\n",
    "  Average Precision = {:.4f},\n",
    "  ROC-AUC = {:.4f}'''.format(\n",
    "       model['model_name'], model['average_precision'], model['roc_auc']))\n",
    "    model['dataset'] = 'MClass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(\n",
    "    [isic_tL_eval, isic_simple_eval, isic_random_eval, \n",
    "     mclass_tL_eval, mclass_simple_eval, mclass_random_eval], \n",
    "    columns=['model_name', 'dataset', 'average_precision', 'roc_auc'])\n",
    "eval_df.set_index(['dataset', 'model_name'], inplace=True, \n",
    "                  verify_integrity=True)\n",
    "# eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_eval = eval_df.copy()\n",
    "d_eval.rename(columns={'average_precision': 'AveP', 'roc_auc': 'AUC'}, \n",
    "              inplace=True)\n",
    "d_eval.index.names = ['Dataset', 'Model']\n",
    "# d_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print LaTeX format\n",
    "print(d_eval.to_latex(float_format=\"{:0.4f}\".format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diagram(fig, ax, model, xkey, ykey, \n",
    "                 xlabel='', ylabel='', title='', style='.-'):\n",
    "    ax.plot(model[xkey], model[ykey], style, \n",
    "            label=model['model_name'], color=model['color'], \n",
    "           linewidth = 0.5)\n",
    "    ax.fill_between(model[xkey], model[ykey]\n",
    "                    , color=model['color'], alpha=0.1)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(models, title='',fig=None, \n",
    "                                ax=None, style='.-'):\n",
    "    if None in (fig, ax):\n",
    "        fig, ax = plt.subplots()\n",
    "    for model in models:\n",
    "        plot_diagram(fig, ax, model, 'recall', 'precision', \n",
    "                     xlabel='Recall', ylabel='Precision', \n",
    "                     title=title, style=style)\n",
    "\n",
    "    ax.grid(linestyle='-', linewidth=0.1)\n",
    "    ax.legend()\n",
    "    return fig,ax\n",
    "\n",
    "def plot_roc_curve(models, title='',fig=None, ax=None, style='.-'):\n",
    "    if None in (fig, ax):\n",
    "        fig, ax = plt.subplots()\n",
    "    for model in models:\n",
    "        plot_diagram(fig, ax, model, 'fpr', 'tpr', \n",
    "                     xlabel='FPR', ylabel='TPR', \n",
    "                     title=title, style=style)\n",
    "\n",
    "    ax.grid(linestyle='-', linewidth=0.1)\n",
    "    ax.legend()\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To uncomment, if you want subplots.\n",
    "# fig, ax_arr = plt.subplots(nrows=1, ncols=2, figsize=(15,7.5))\n",
    "# fig, ax_arr[0] = plot_precision_recall_curve(\n",
    "#     (isic_tL_eval, \n",
    "#      isic_simple_eval, \n",
    "#      isic_random_eval), \n",
    "#     'Precision-Recall-Diagramm - ISIC 2016',\n",
    "#     fig=fig, ax=ax_arr[0],\n",
    "# )\n",
    "# ax_arr[0].set_aspect('equal')\n",
    "# #ax_arr[0].set_xlim(0,1)\n",
    "# #ax_arr[0].set_ylim(0,1)\n",
    "\n",
    "# fig, ax_arr[1] = plot_roc_curve(\n",
    "#     (isic_tL_eval, \n",
    "#      isic_simple_eval, \n",
    "#      isic_random_eval), \n",
    "#     'ROC Analyse - ISIC 2016',\n",
    "#     fig=fig, ax=ax_arr[1],\n",
    "# )\n",
    "# ax_arr[1].set_aspect('equal')\n",
    "\n",
    "\n",
    "# fig.savefig(\n",
    "#     '../results/ISIC2016_subplots.pdf',\n",
    "#     bbox_inches='tight',\n",
    "#     pad_inches=0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plot_precision_recall_curve(\n",
    "    (isic_tL_eval, \n",
    "     isic_simple_eval, \n",
    "     isic_random_eval), \n",
    "    'Precision-Recall - ISIC 2016',\n",
    ")\n",
    "fig1.savefig(\n",
    "    '../results/prc-ISIC2016.pdf',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plot_roc_curve(\n",
    "    (isic_tL_eval, \n",
    "     isic_simple_eval, \n",
    "     isic_random_eval), \n",
    "    'ROC Analysis - ISIC 2016')\n",
    "fig2.savefig(\n",
    "    '../results/roc-ISIC2016.pdf',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, ax3 = plot_precision_recall_curve(\n",
    "    (mclass_tL_eval, \n",
    "     mclass_simple_eval, \n",
    "     mclass_random_eval), \n",
    "    'Precision-Recall - MClass')\n",
    "fig3.savefig(\n",
    "    '../results/prc-mclass.pdf',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, ax4 = plot_roc_curve(\n",
    "    (mclass_tL_eval, \n",
    "     mclass_simple_eval, \n",
    "     mclass_random_eval), \n",
    "    'ROC Analysis  - MClass')\n",
    "fig4.savefig(\n",
    "    '../results/roc-mclass.pdf',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Dermatologists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclass_dermatologist_results = pd.read_csv(\n",
    "    '../metadata/MClass_ResultsDermoscopic.csv', index_col='Dermatologist')\n",
    "mclass_dermatologist_results.replace(\n",
    "    to_replace='biopsy / further treatment', value=1, inplace=True)\n",
    "mclass_dermatologist_results.replace(\n",
    "    to_replace='no further treatment', value=0, inplace=True)\n",
    "mclass_dermatologist_results.rename(\n",
    "    inplace=True,\n",
    "    columns={s:i for s,i in zip(\n",
    "        mclass_dermatologist_results.columns, \n",
    "        range(0, len(mclass_dermatologist_results.columns)))})\n",
    "mclass_dermatologist_results = mclass_dermatologist_results.transpose()\n",
    "mclass_dermatologist_results\n",
    "mclass_dermatologist_results.index.name = 'id'\n",
    "mclass_dermatologist_results.rename(\n",
    "    inplace=True,\n",
    "    index=dict(mclass['id'])\n",
    ")\n",
    "# mclass_dermatologist_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mclass_recall(y_pred):\n",
    "    return recall_score(mclass['y_true'], y_pred)\n",
    "\n",
    "dermatologist_recall = mclass_dermatologist_results.apply(mclass_recall, \n",
    "                                                          axis=0)\n",
    "\n",
    "def mclass_precision(y_pred):\n",
    "    return precision_score(mclass['y_true'], y_pred)\n",
    "\n",
    "def mclass_fpr(y_pred):\n",
    "    conf_matrix = confusion_matrix(mclass['y_true'], y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(mclass['y_true'], y_pred).ravel()\n",
    "\n",
    "    fpr = fp / (fp+tn)\n",
    "    return fpr\n",
    "\n",
    "dermatologist_recall = mclass_dermatologist_results.apply(\n",
    "    mclass_recall, axis=0)\n",
    "dermatologist_precision = mclass_dermatologist_results.apply(\n",
    "    mclass_precision, axis=0)\n",
    "\n",
    "dermatologist_fpr = mclass_dermatologist_results.apply(\n",
    "    mclass_fpr, axis = 0)\n",
    "\n",
    "dermatologist_evaluation = pd.DataFrame(data={\n",
    "    'recall': dermatologist_recall,\n",
    "    'precision': dermatologist_precision,\n",
    "    'fpr': dermatologist_fpr})\n",
    "#dermatologist_evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5, ax5 = plt.subplots(nrows=1, ncols=1, figsize=(8,6))\n",
    "fig5, ax5 = plot_precision_recall_curve(\n",
    "    (mclass_tL_eval,), \n",
    "    'Precision-Recall - MClass, Dermatologists',style='-',\n",
    "    fig=fig5, ax=ax5,\n",
    ")\n",
    "ax5.plot(\n",
    "    dermatologist_recall, \n",
    "    dermatologist_precision, '.g', label='Dermatologists')\n",
    "ax5.legend()\n",
    "fig5.savefig(\n",
    "    '../results/prc-mclass-dermatologists.pdf',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6, ax6 = plt.subplots(nrows=1, ncols=1, figsize=(8,6))\n",
    "\n",
    "fig6, ax6 = plot_roc_curve(\n",
    "    (mclass_tL_eval,), \n",
    "    'ROC Analyse - MClass, Dermatologists',style='-',\n",
    "    fig=fig6, ax=ax6,\n",
    ")\n",
    "ax6.plot(\n",
    "    dermatologist_fpr, \n",
    "    dermatologist_recall, '.g', label='Dermatologists')\n",
    "ax6.legend(loc='lower right')\n",
    "fig6.savefig(\n",
    "    '../results/roc-mclass-dermatologists.pdf',\n",
    "    bbox_inches='tight',\n",
    "    pad_inches=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tL_probas_mal = mclass['y_score_two_Layer'][mclass['y_true']==1]\n",
    "tL_probas_ben = mclass['y_score_two_Layer'][mclass['y_true']==0]\n",
    "\n",
    "fig7, ax7 = plt.subplots()\n",
    "ax7.boxplot([tL_probas_mal, tL_probas_ben], labels =['malignant', 'benign'], \n",
    "                #showfliers=False,\n",
    "                #whis=1.2\n",
    ")\n",
    "ax7.set_ylabel('Model-Score')\n",
    "ax7.set_title('MClass: twoLayer Model scores for each category')\n",
    "fig7.savefig('../results/boxplot.pdf',\n",
    "            bbox_inches='tight',\n",
    "             pad_inches=0,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show images of the program excelling and failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclass[mclass['y_true']==0].sort_values(\n",
    "    by=['y_score_two_Layer']).head()#['id.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig8, ax8 = plt.subplots(nrows = 4, ncols=5, \n",
    "                         gridspec_kw={'hspace': 0, 'wspace': 0}, \n",
    "                         figsize=(5, 4))\n",
    "\n",
    "for ax, fname in zip(\n",
    "        ax8[0], \n",
    "        mclass[mclass['y_true']==1].sort_values(\n",
    "            by=['y_score_two_Layer']).tail(5)['id.1']):\n",
    "    ax.axis('Off')\n",
    "    img = mpimg.imread('../Images/' + fname)\n",
    "    imgplot = ax.imshow(img,)\n",
    "    \n",
    "    \n",
    "    \n",
    "for ax, fname in zip(\n",
    "        ax8[1], \n",
    "        mclass[mclass['y_true']==1].sort_values(\n",
    "            by=['y_score_two_Layer']).head(5)['id.1']):\n",
    "    ax.axis('Off')\n",
    "    img = mpimg.imread('../Images/' + fname)\n",
    "    imgplot = ax.imshow(img,)\n",
    "    \n",
    "for ax, fname in zip(\n",
    "        ax8[2], \n",
    "        mclass[mclass['y_true']==0].sort_values(\n",
    "            by=['y_score_two_Layer']).head(5)['id.1']):\n",
    "    ax.axis('Off')\n",
    "    img = mpimg.imread('../Images/' + fname)\n",
    "    imgplot = ax.imshow(img,)\n",
    "    \n",
    "for ax, fname in zip(\n",
    "        ax8[3], \n",
    "        mclass[mclass['y_true']==0].sort_values(\n",
    "            by=['y_score_two_Layer']).tail(5)['id.1']):\n",
    "    ax.axis('Off')\n",
    "    img = mpimg.imread('../Images/' + fname)\n",
    "    imgplot = ax.imshow(img,)\n",
    "    \n",
    "    \n",
    "fig8.subplots_adjust(bottom=0, left=0, right=1, top=1)\n",
    "    \n",
    "    \n",
    "fig8.savefig('../results/images_rows.pdf', dpi=300, \n",
    "             bbox_inches='tight',\n",
    "             pad_inches=0,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count points inside polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precision - recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclass_tL_precision = mclass_tL_eval['precision']\n",
    "mclass_tL_recall = mclass_tL_eval['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclass_tL_precision_polygon = np.append(mclass_tL_precision, [0, 0])\n",
    "mclass_tL_recall_polygon = np.append(mclass_tL_recall, [1, 0])\n",
    "# mclass_tL_precision_polygon\n",
    "# mclass_tL_recall_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_polyg = Polygon([(x,y) for (x,y) in zip(\n",
    "    mclass_tL_recall_polygon, mclass_tL_precision_polygon)])\n",
    "# prc_polyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_points_list = [Point(x,y) for x, y in zip(\n",
    "    dermatologist_recall, dermatologist_precision)]\n",
    "# prc_points_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_inside = pd.Series([prc_polyg.contains(p) for p in prc_points_list])\n",
    "prc_touch = pd.Series([prc_polyg.touches(p) for p in prc_points_list])\n",
    "prc_disjoint = pd.Series([prc_polyg.disjoint(p) for p in prc_points_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prc_inside.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prc_touch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prc_disjoint.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclass_tL_ = mclass_tL_eval['precision']\n",
    "mclass_tL_recall = mclass_tL_eval['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclass_tL_fpr = mclass_tL_eval['fpr']\n",
    "mclass_tL_tpr = mclass_tL_eval['tpr']\n",
    "# mclass_tL_fpr\n",
    "# mclass_tL_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclass_tL_fpr_polygon = np.append(mclass_tL_fpr, [1])\n",
    "mclass_tL_tpr_polygon = np.append(mclass_tL_tpr, [0])\n",
    "# mclass_tL_fpr_polygon\n",
    "# mclass_tL_tpr_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_polyg = Polygon([(x,y) for (x,y) in zip(\n",
    "    mclass_tL_fpr_polygon, mclass_tL_tpr_polygon)])\n",
    "# roc_polyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_points_list = [Point(x,y) for x, y in zip(\n",
    "    dermatologist_fpr, dermatologist_recall)]\n",
    "# roc_points_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_inside = pd.Series([roc_polyg.contains(p) for p in roc_points_list])\n",
    "roc_touch = pd.Series([roc_polyg.touches(p) for p in roc_points_list])\n",
    "roc_disjoint = pd.Series([roc_polyg.disjoint(p) for p in roc_points_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_inside.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_touch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_disjoint.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_eval_df = pd.DataFrame(\n",
    "    {\n",
    "        'd_fpr': list(dermatologist_fpr),\n",
    "        'd_recall': list(dermatologist_recall),\n",
    "        'd_precision': list(dermatologist_precision),\n",
    "        'prc_inside': prc_inside,\n",
    "        'prc_touch': prc_touch,\n",
    "        'prc_disjoint': prc_disjoint,\n",
    "        'roc_inside': roc_inside,\n",
    "        'roc_touch': roc_touch,\n",
    "        'roc_disjoint': roc_disjoint,\n",
    "    \n",
    "    })\n",
    "# points_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_points_eval = pd.Series(\n",
    "    {key:val.value_counts()[True] for (key,val) in zip(\n",
    "        ('below', 'on', 'above'), (roc_inside, roc_touch, roc_disjoint))})\n",
    "prc_points_eval = pd.Series(\n",
    "    {key:val.value_counts()[True] for (key,val) in zip(\n",
    "        ('below', 'on', 'above'), (prc_inside, prc_touch, prc_disjoint))})\n",
    "points_df = pd.DataFrame({'PRC': prc_points_eval, 'ROC':roc_points_eval})\n",
    "\n",
    "# roc_points_eval\n",
    "# prc_points_eval\n",
    "# points_df\n",
    "print(points_df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pictures from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = mc.training_set\n",
    "# ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_malignant = ts[ts['category']=='malignant']\n",
    "malignant_ts = shuffle(ts_malignant, random_state=1).head(5)\n",
    "# malignant_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_benign = ts[ts['category']=='benign']\n",
    "benign_ts = shuffle(ts_benign, random_state=10).head(5)\n",
    "# benign_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig9, ax9 = plt.subplots(nrows = 2, ncols=5, \n",
    "                         gridspec_kw={'hspace': 0, 'wspace': 0}, \n",
    "                         figsize=(5, 2))\n",
    "\n",
    "for ax, fname in zip(\n",
    "        ax9[0], \n",
    "        malignant_ts['id']):\n",
    "    ax.axis('Off')\n",
    "    img = mpimg.imread('../Images/' + fname)\n",
    "    imgplot = ax.imshow(img,)\n",
    "    \n",
    "    \n",
    "    \n",
    "for ax, fname in zip(\n",
    "        ax9[1], \n",
    "        benign_ts['id']):\n",
    "    ax.axis('Off')\n",
    "    img = mpimg.imread('../Images/' + fname)\n",
    "    imgplot = ax.imshow(img,)\n",
    "    \n",
    "   \n",
    "    \n",
    "fig9.subplots_adjust(bottom=0, left=0, right=1, top=1)\n",
    "    \n",
    "    \n",
    "fig9.savefig('../results/images_training_set.pdf', dpi=300, \n",
    "             bbox_inches='tight',\n",
    "             pad_inches=0,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random: Explanation of the Precision-Recall curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isic2016['y_score_random'] = isic_random_y_scores\n",
    "random_sorted = list(isic2016.sort_values(\n",
    "    by='y_score_random')['category'].replace(\n",
    "    to_replace={'benign':0, 'malignant':1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sorted[-10:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
